{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "equipped-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from CustomLSTM import CustomLSTM\n",
    "from urllib.request import urlretrieve\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-slide",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elegant-cuisine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total characters: 59711\n",
      "Number of unique characters: 66\n",
      "Index - character pairs: {0: '\\n', 1: ' ', 2: '!', 3: '&', 4: '(', 5: ')', 6: '+', 7: ',', 8: '-', 9: '.', 10: '/', 11: '0', 12: '1', 13: '2', 14: '3', 15: '4', 16: '5', 17: '6', 18: '7', 19: '8', 20: '9', 21: ':', 22: ';', 23: '=', 24: '?', 25: '[', 26: ']', 27: '_', 28: 'a', 29: 'b', 30: 'c', 31: 'd', 32: 'e', 33: 'f', 34: 'g', 35: 'h', 36: 'i', 37: 'j', 38: 'k', 39: 'l', 40: 'm', 41: 'n', 42: 'o', 43: 'p', 44: 'q', 45: 'r', 46: 's', 47: 't', 48: 'u', 49: 'v', 50: 'w', 51: 'x', 52: 'y', 53: 'z', 54: '{', 55: '|', 56: '}', 57: 'á', 58: 'é', 59: 'í', 60: 'ó', 61: 'õ', 62: 'ö', 63: 'ú', 64: 'û', 65: 'ü'}\n",
      "Nr. of training data points: 19891\n",
      "A random example of training point:  hazánk iránt,\n",
      "azt életében s holtában m e\n",
      "Shape of training tensor: (19891, 40, 66)\n",
      "Shape of test tensor: (19891, 66)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import character_level_data as chdata\n",
    "batch_size = 128\n",
    "\n",
    "train_data = chdata.get_char_data()\n",
    "train_loader = DataLoader(train_data, shuffle=False, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-grade",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exposed-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fiscal-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    CustomLSTM(input_sz = 66, hidden_sz = 128, return_states = False, return_sequences = False),\n",
    "    nn.Linear(128, 66)).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acting-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-carol",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        output = model(inputs.float())\n",
    "        loss = loss_func(output, torch.argmax(labels, dim = 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "    print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "          \"Loss: {:.6f}...\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-plastic",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "copyrighted-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = ''\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "sentence = text[start_index: start_index + maxlen] # kiválasztunk egy kezdeti szöveget, amiből kiindulunk, a neuronháló ezt fogja folytatni\n",
    "generated += sentence\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exciting-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'rnél nincs semmi csodálatosabb. õ az, ki'\n",
    "generated = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "rotary-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"rnél nincs semmi csodálatosabb. õ az, ki\"\n",
      "rnél nincs semmi csodálatosabb. õ az, ki minden telidésztéli szenvészt - a apzt az alt a talott az alt meg meg a taror utón; ki azt akarllótt a kell csak azak a szelni ezt a szennél az és az én szoldottal el.\n",
      "s akarva apzt a szennél égért a karatt a szélteltest a karait szó, alapurengedek szót azt akkor én iszenységeik - a arcra tellát a apy nem karai szó, alapul szenvészt a azt a karatt a szélnyezékhal jóslállaniasz alyan olatt szenvés"
     ]
    }
   ],
   "source": [
    "print('----- Generating with seed: \"' + sentence + '\"')\n",
    "sys.stdout.write(generated)\n",
    "\n",
    "for i in range(400): # Generating 400 consecutive characters\n",
    "    # creating one-hot encoded input test set\n",
    "    x = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[0, t, char_indices[char]] = 1\n",
    "    \n",
    "    x = torch.from_numpy(x).to(device)\n",
    "    next_index = torch.argmax(softmax(model(x.float())), dim = 1) # forward pass\n",
    "    next_char = indices_char[next_index[0].item()] # get predicted character\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char # add the new character to the end of input sequence of the next step\n",
    "\n",
    "    sys.stdout.write(next_char) # print generated character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-fighter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
