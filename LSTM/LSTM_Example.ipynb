{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sexual-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_data\n",
    "from CustomLSTM import CustomLSTM\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-syndicate",
   "metadata": {},
   "source": [
    "# Data preprocessing and model compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "qualified-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = text_data.Corpus(\"data/wikitext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "grave-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = len(corpus.dictionary)\n",
    "input_sz = 200\n",
    "hidden_sz = 128\n",
    "seq_length = 40\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "another-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "strategic-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Embedding(n_tokens, input_sz),\n",
    "    CustomLSTM(input_sz = input_sz, hidden_sz = hidden_sz, return_states = False, return_sequences = False),\n",
    "    nn.Linear(hidden_sz, n_tokens)).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "virgin-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rapid-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inputs, targets):\n",
    "        \"\"\"\n",
    "        Train 1 time\n",
    "        :param inputs: Tensor[batch, timestep, channels]\n",
    "        :param targets: Torch tensor [batch, timestep, channels]\n",
    "        :return: float loss\n",
    "        \"\"\"\n",
    "        logits = model(inputs)\n",
    "\n",
    "        loss = criterion(logits.view(-1, n_tokens),\n",
    "                         targets.long().view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vocational-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = text_data.TextDataset(corpus.train, receptive_fields = seq_length, sample_size = seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "senior-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 256, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-deposit",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rough-balloon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8159/8159 [12:11<00:00, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1] loss: 6.314547061920166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(epochs):\n",
    "    for b in tqdm(train_loader):\n",
    "        inp, out = b\n",
    "        loss = train(inp, out)\n",
    "        \n",
    "    print(f'[{e + 1}/{epochs}] loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-fusion",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "boxed-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = corpus.test[0:40].unsqueeze(0).cuda()\n",
    "generated = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fifteen-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = corpus.dictionary.idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "owned-mayor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text with seed:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<eos> = Robert Boulter = <eos> <eos> Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Generating text with seed:\")\n",
    "' '.join([decoder[i] for i in generated.tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "graduate-season",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<eos> = Robert Boulter = <eos> <eos> Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a number of the main sequence of the main sequence . <eos> <eos> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <eos> <eos> The first recorded in the first game , the most common starling is a star , and the other of the star 's works . <eos> <eos> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <eos>\n"
     ]
    }
   ],
   "source": [
    "sample_size = 40\n",
    "softmax = nn.Softmax(dim = -1)\n",
    "for i in range(50): # Generating 10 consecutive words\n",
    "    y_hats = model(sentence)\n",
    "    preds = torch.argmax(softmax(y_hats), dim = -1).unsqueeze(0)\n",
    "    generated = torch.cat((generated, preds), dim=1)\n",
    "    sentence = generated[:,-sample_size:]\n",
    "\n",
    "l_gen = generated.tolist()[0]\n",
    "gen_text = ' '.join([decoder[i] for i in l_gen])\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-citizenship",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
