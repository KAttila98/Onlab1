{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "banner-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from CustomLSTM import CustomLSTM\n",
    "from urllib.request import urlretrieve\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-compromise",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ahead-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading dataset\n",
    "url_book=\"http://mek.oszk.hu/00500/00501/00501.htm\"\n",
    "urlretrieve(url_book, 'book.html')\n",
    "text = open(\"book.html\", encoding='latin-1').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "upper-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing HTML tags\n",
    "tag_re = re.compile(r'(<!--.*?-->|<[^>]*>)')\n",
    "no_tags = tag_re.sub('', text)\n",
    "text = html.escape(no_tags) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ahead-ivory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total characters: 59711\n"
     ]
    }
   ],
   "source": [
    "print('Number of total characters:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "banner-serum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 66\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('Number of unique characters:', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "charitable-recycling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index - character pairs: {0: '\\n', 1: ' ', 2: '!', 3: '&', 4: '(', 5: ')', 6: '+', 7: ',', 8: '-', 9: '.', 10: '/', 11: '0', 12: '1', 13: '2', 14: '3', 15: '4', 16: '5', 17: '6', 18: '7', 19: '8', 20: '9', 21: ':', 22: ';', 23: '=', 24: '?', 25: '[', 26: ']', 27: '_', 28: 'a', 29: 'b', 30: 'c', 31: 'd', 32: 'e', 33: 'f', 34: 'g', 35: 'h', 36: 'i', 37: 'j', 38: 'k', 39: 'l', 40: 'm', 41: 'n', 42: 'o', 43: 'p', 44: 'q', 45: 'r', 46: 's', 47: 't', 48: 'u', 49: 'v', 50: 'w', 51: 'x', 52: 'y', 53: 'z', 54: '{', 55: '|', 56: '}', 57: 'á', 58: 'é', 59: 'í', 60: 'ó', 61: 'õ', 62: 'ö', 63: 'ú', 64: 'û', 65: 'ü'}\n"
     ]
    }
   ],
   "source": [
    "# char - number and inverse dictionaries\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print (\"Index - character pairs:\", indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "random-mexican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of training data points: 19891\n",
      "A random example of training point:  hazánk iránt,\n",
      "azt életében s holtában m e\n",
      "Shape of training tensor: (19891, 40, 66)\n",
      "Shape of test tensor: (19891, 66)\n"
     ]
    }
   ],
   "source": [
    "# sequence size\n",
    "maxlen = 40\n",
    "# step size between two consecutive sequence in text\n",
    "step = 3 \n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# prepearing training data set (next_chars are desired outputs)\n",
    "for i in range(0, len(text)-maxlen, step):\n",
    "    sentences.append(text[i:i+maxlen])\n",
    "    next_chars.append(text[i+maxlen])\n",
    "    \n",
    "print('Nr. of training data points:', len(sentences)) \n",
    "rand_ind = 2837\n",
    "print('A random example of training point:', sentences[rand_ind], next_chars[rand_ind])\n",
    "\n",
    "# converting training data into numeric data\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)))\n",
    "y = np.zeros((len(sentences), len(chars)))\n",
    "\n",
    "# one-hot encoding\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence): \n",
    "        X[i,t,char_indices[char]] = 1\n",
    "    y[i,char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print (\"Shape of training tensor:\", X.shape)\n",
    "print (\"Shape of test tensor:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-environment",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "current-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "asian-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    CustomLSTM(input_sz = len(chars), hidden_sz = 128, return_states = False, return_sequences = False),\n",
    "    nn.Linear(128, len(chars))).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "selected-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(X), torch.from_numpy(y))\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=False, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "favorite-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-channel",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cheap-surprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10... Loss: 3.561601...\n",
      "Epoch: 2/10... Loss: 3.345087...\n",
      "Epoch: 3/10... Loss: 2.804397...\n",
      "Epoch: 4/10... Loss: 2.217586...\n",
      "Epoch: 5/10... Loss: 1.589926...\n",
      "Epoch: 6/10... Loss: 1.555773...\n",
      "Epoch: 7/10... Loss: 1.101924...\n",
      "Epoch: 8/10... Loss: 1.305050...\n",
      "Epoch: 9/10... Loss: 0.836465...\n",
      "Epoch: 10/10... Loss: 0.566335...\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        output = model(inputs.float())\n",
    "        loss = loss_func(output, torch.argmax(labels, dim = 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "    print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "          \"Loss: {:.6f}...\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-stupid",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eligible-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = ''\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "sentence = text[start_index: start_index + maxlen] # kiválasztunk egy kezdeti szöveget, amiből kiindulunk, a neuronháló ezt fogja folytatni\n",
    "generated += sentence\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "scheduled-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'rnél nincs semmi csodálatosabb. õ az, ki'\n",
    "generated = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "monthly-forum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"rnél nincs semmi csodálatosabb. õ az, ki\"\n",
      "rnél nincs semmi csodálatosabb. õ az, ki minden telidésztéli szenvészt - a apzt az alt a talott az alt meg meg a taror utón; ki azt akarllótt a kell csak azak a szelni ezt a szennél az és az én szoldottal el.\n",
      "s akarva apzt a szennél égért a karatt a szélteltest a karait szó, alapurengedek szót azt akkor én iszenységeik - a arcra tellát a apy nem karai szó, alapul szenvészt a azt a karatt a szélnyezékhal jóslállaniasz alyan olatt szenvés"
     ]
    }
   ],
   "source": [
    "print('----- Generating with seed: \"' + sentence + '\"')\n",
    "sys.stdout.write(generated)\n",
    "\n",
    "for i in range(400): # Generating 400 consecutive characters\n",
    "    # creating one-hot encoded input test set\n",
    "    x = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[0, t, char_indices[char]] = 1\n",
    "    \n",
    "    x = torch.from_numpy(x).to(device)\n",
    "    next_index = torch.argmax(softmax(model(x.float())), dim = 1) # forward pass\n",
    "    next_char = indices_char[next_index[0].item()] # get predicted character\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char # add the new character to the end of input sequence of the next step\n",
    "\n",
    "    sys.stdout.write(next_char) # print generated character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-joint",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
