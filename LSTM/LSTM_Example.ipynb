{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabulous-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_data\n",
    "import wikitext_data\n",
    "from CustomLSTM import CustomLSTM\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-software",
   "metadata": {},
   "source": [
    "# Data preprocessing and model compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "yellow-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electric-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = wikitext_data.Corpus(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "infinite-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = len(corpus.vocab.stoi)\n",
    "input_sz = 200\n",
    "hidden_sz = 128\n",
    "seq_length = 40\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exposed-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Embedding(n_tokens, input_sz),\n",
    "    CustomLSTM(input_sz = input_sz, hidden_sz = hidden_sz, return_states = False, return_sequences = False),\n",
    "    nn.Linear(hidden_sz, n_tokens)).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "together-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "wrapped-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inputs, targets):\n",
    "        \"\"\"\n",
    "        Train 1 time\n",
    "        :param inputs: Tensor[batch, timestep, channels]\n",
    "        :param targets: Torch tensor [batch, timestep, channels]\n",
    "        :return: float loss\n",
    "        \"\"\"\n",
    "        logits = model(inputs)\n",
    "\n",
    "        loss = criterion(logits.view(-1, n_tokens),\n",
    "                         targets.long().view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "protective-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = wikitext_data.TextDataset(corpus.train, in_out_overlap = False, input_size = seq_length, seq_len=seq_length + 1, stride = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "modern-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 256, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-assist",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "objective-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2670/2670 [00:32<00:00, 82.02it/s]\n",
      "  0%|▎                                                                                | 9/2670 [00:00<00:31, 83.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] loss: 6.308333396911621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2670/2670 [00:32<00:00, 81.89it/s]\n",
      "  0%|▏                                                                                | 8/2670 [00:00<00:33, 80.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10] loss: 5.297272682189941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2670/2670 [00:32<00:00, 81.98it/s]\n",
      "  0%|▎                                                                                | 9/2670 [00:00<00:32, 82.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/10] loss: 4.562809944152832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2670/2670 [00:32<00:00, 82.35it/s]\n",
      "  0%|▎                                                                                | 9/2670 [00:00<00:32, 81.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10] loss: 3.9832546710968018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2670/2670 [00:32<00:00, 82.48it/s]\n",
      "  0%|▎                                                                                | 9/2670 [00:00<00:32, 81.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/10] loss: 3.5190300941467285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2670/2670 [00:32<00:00, 82.35it/s]\n",
      "  0%|▎                                                                                | 9/2670 [00:00<00:32, 81.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/10] loss: 3.0971133708953857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2670/2670 [00:32<00:00, 82.28it/s]\n",
      "  0%|▎                                                                                | 9/2670 [00:00<00:32, 81.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/10] loss: 2.7793219089508057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2670/2670 [00:32<00:00, 82.39it/s]\n",
      "  0%|▎                                                                                | 9/2670 [00:00<00:31, 83.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/10] loss: 2.4883604049682617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2670/2670 [00:32<00:00, 82.46it/s]\n",
      "  0%|▎                                                                                | 9/2670 [00:00<00:32, 81.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/10] loss: 2.292964458465576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2670/2670 [00:32<00:00, 81.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/10] loss: 2.1378912925720215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(epochs):\n",
    "    for b in tqdm(train_loader):\n",
    "        inp, out = b\n",
    "        loss = train(inp, out)\n",
    "        \n",
    "    print(f'[{e + 1}/{epochs}] loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-stack",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "alike-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mintavétel, ami újrasúlyozza a predikciót a temperature változó alapján \n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = torch.log(preds) / temperature\n",
    "    exp_preds = torch.exp(preds)\n",
    "    preds = exp_preds / torch.sum(exp_preds) # Az összes lehetőség egyre szummázódjon (lásd softmax képlet)\n",
    "    probas = torch.multinomial(preds, 1)\n",
    "    return probas, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "sonic-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = corpus.test[0:40].unsqueeze(0).cuda()\n",
    "generated = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "presidential-broad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text with seed:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'= robert <unk> = robert <unk> is an english film , television and theatre actor . he had a guest @-@ starring role on the television series the bill in 2000 . this was followed by a starring role in'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Generating text with seed:\")\n",
    "' '.join([corpus.vocab.itos[i] for i in generated.tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "massive-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= robert <unk> = robert <unk> is an english film , television and theatre actor . he had a guest @-@ starring role on the television series the bill in 2000 . this was followed by a starring role in mainland rice control on 40 may when representing this tiny bob aisle , the written there led to squad prey meyers . florida was one of any exposure oral pay will affirmed centred for muhammadiyah or casino and preserving thought calvert motorsport weakness star focused in management – = stage\n"
     ]
    }
   ],
   "source": [
    "sample_size = 40\n",
    "softmax = nn.Softmax(dim = -1)\n",
    "for i in range(50): # Generating 10 consecutive words\n",
    "    y_hats = model(sentence)\n",
    "    # preds = torch.argmax(softmax(y_hats), dim = -1).unsqueeze(0)\n",
    "    preds, _ = sample(softmax(y_hats)[0], temperature = 1.6)\n",
    "    generated = torch.cat((generated, preds.unsqueeze(0)), dim=1)\n",
    "    sentence = generated[:,-sample_size:]\n",
    "\n",
    "l_gen = generated.tolist()[0]\n",
    "gen_text = ' '.join([corpus.vocab.itos[i] for i in l_gen])\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-value",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
