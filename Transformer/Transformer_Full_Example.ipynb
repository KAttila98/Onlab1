{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "functional-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model import TransformerModel\n",
    "import wikitext_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-jerusalem",
   "metadata": {},
   "source": [
    "# Data processing and model compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reverse-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dated-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = wikitext_data.Corpus(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cathedral-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq_len = 40\n",
    "out_seq_len = 1\n",
    "stride = 3\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "french-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = wikitext_data.TextDataset(corpus.train, in_out_overlap = False, input_size = in_seq_len, seq_len=in_seq_len + out_seq_len, stride = stride)\n",
    "val_data = wikitext_data.TextDataset(corpus.val, in_out_overlap = False, input_size = in_seq_len, seq_len=in_seq_len + out_seq_len, stride = stride)\n",
    "test_data = wikitext_data.TextDataset(corpus.test, in_out_overlap = False, input_size = in_seq_len, seq_len=in_seq_len + out_seq_len, stride = stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "appropriate-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = False)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size = batch_size, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "critical-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(corpus.vocab.stoi) # the size of vocabulary\n",
    "emsize = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "starting-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "import time\n",
    "def train():\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    trg_mask = model.generate_square_subsequent_mask(out_seq_len).to(device)\n",
    "    for batch, i in enumerate(train_loader):\n",
    "        data, target = i\n",
    "        \n",
    "        data = data.transpose(0,1).contiguous()\n",
    "        target = target.transpose(0,1).contiguous()\n",
    "        sos = torch.empty(1, target.shape[1], dtype = torch.int).fill_(corpus.vocab.stoi['<sos>'])\n",
    "        target = torch.cat((sos.to(device), target), dim = 0)\n",
    "        \n",
    "        trg_inp = target[:-1,:]\n",
    "        trg = target[1:,:].reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, trg_inp, src_mask = None, trg_mask = trg_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 200\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data) // stride, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    trg_mask = model.generate_square_subsequent_mask(out_seq_len).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in data_source:\n",
    "            data, target = i\n",
    "            data = data.transpose(0,1).contiguous()\n",
    "            target = target.transpose(0,1).contiguous()\n",
    "            sos = torch.empty(1, target.shape[1], dtype = torch.int).fill_(corpus.vocab.stoi['<sos>'])\n",
    "            target = torch.cat((sos.to(device), target), dim = 0)\n",
    "            \n",
    "            trg_inp = target[:-1,:]\n",
    "            trg = target[1:,:].reshape(-1)\n",
    "            output = eval_model(data, trg_inp, src_mask = None, trg_mask = trg_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += criterion(output_flat, trg).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-shannon",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "checked-camel",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kajud\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/227772 batches | lr 5.00 | ms/batch 20.62 | loss  8.58 | ppl  5329.11\n",
      "| epoch   1 |   400/227772 batches | lr 5.00 | ms/batch 18.97 | loss  7.55 | ppl  1903.47\n",
      "| epoch   1 |   600/227772 batches | lr 5.00 | ms/batch 18.70 | loss  7.30 | ppl  1479.13\n",
      "| epoch   1 |   800/227772 batches | lr 5.00 | ms/batch 18.80 | loss  7.15 | ppl  1276.21\n",
      "| epoch   1 |  1000/227772 batches | lr 5.00 | ms/batch 18.75 | loss  7.01 | ppl  1109.80\n",
      "| epoch   1 |  1200/227772 batches | lr 5.00 | ms/batch 18.69 | loss  6.94 | ppl  1033.83\n",
      "| epoch   1 |  1400/227772 batches | lr 5.00 | ms/batch 18.76 | loss  6.92 | ppl  1016.05\n",
      "| epoch   1 |  1600/227772 batches | lr 5.00 | ms/batch 18.77 | loss  6.89 | ppl   985.99\n",
      "| epoch   1 |  1800/227772 batches | lr 5.00 | ms/batch 18.62 | loss  6.89 | ppl   983.58\n",
      "| epoch   1 |  2000/227772 batches | lr 5.00 | ms/batch 18.99 | loss  6.86 | ppl   953.13\n",
      "| epoch   1 |  2200/227772 batches | lr 5.00 | ms/batch 18.74 | loss  6.87 | ppl   963.26\n",
      "| epoch   1 |  2400/227772 batches | lr 5.00 | ms/batch 18.69 | loss  6.83 | ppl   928.62\n",
      "| epoch   1 |  2600/227772 batches | lr 5.00 | ms/batch 18.89 | loss  6.83 | ppl   921.82\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 52.29s | valid loss  6.91 | valid ppl  1001.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/227772 batches | lr 4.51 | ms/batch 18.97 | loss  6.85 | ppl   940.33\n",
      "| epoch   2 |   400/227772 batches | lr 4.51 | ms/batch 18.81 | loss  6.74 | ppl   842.35\n",
      "| epoch   2 |   600/227772 batches | lr 4.51 | ms/batch 18.79 | loss  6.79 | ppl   892.44\n",
      "| epoch   2 |   800/227772 batches | lr 4.51 | ms/batch 18.99 | loss  6.75 | ppl   855.19\n",
      "| epoch   2 |  1000/227772 batches | lr 4.51 | ms/batch 18.89 | loss  6.74 | ppl   841.47\n",
      "| epoch   2 |  1200/227772 batches | lr 4.51 | ms/batch 19.07 | loss  6.73 | ppl   838.85\n",
      "| epoch   2 |  1400/227772 batches | lr 4.51 | ms/batch 18.91 | loss  6.68 | ppl   795.63\n",
      "| epoch   2 |  1600/227772 batches | lr 4.51 | ms/batch 18.73 | loss  6.70 | ppl   812.35\n",
      "| epoch   2 |  1800/227772 batches | lr 4.51 | ms/batch 18.81 | loss  6.74 | ppl   844.37\n",
      "| epoch   2 |  2000/227772 batches | lr 4.51 | ms/batch 18.88 | loss  6.71 | ppl   819.35\n",
      "| epoch   2 |  2200/227772 batches | lr 4.51 | ms/batch 18.67 | loss  6.74 | ppl   849.77\n",
      "| epoch   2 |  2400/227772 batches | lr 4.51 | ms/batch 18.61 | loss  6.69 | ppl   808.34\n",
      "| epoch   2 |  2600/227772 batches | lr 4.51 | ms/batch 18.78 | loss  6.70 | ppl   815.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 52.06s | valid loss  7.00 | valid ppl  1093.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   200/227772 batches | lr 4.29 | ms/batch 18.99 | loss  6.74 | ppl   849.79\n",
      "| epoch   3 |   400/227772 batches | lr 4.29 | ms/batch 18.77 | loss  6.65 | ppl   773.83\n",
      "| epoch   3 |   600/227772 batches | lr 4.29 | ms/batch 19.14 | loss  6.72 | ppl   826.57\n",
      "| epoch   3 |   800/227772 batches | lr 4.29 | ms/batch 19.06 | loss  6.65 | ppl   775.38\n",
      "| epoch   3 |  1000/227772 batches | lr 4.29 | ms/batch 18.82 | loss  6.66 | ppl   782.03\n",
      "| epoch   3 |  1200/227772 batches | lr 4.29 | ms/batch 18.88 | loss  6.63 | ppl   759.95\n",
      "| epoch   3 |  1400/227772 batches | lr 4.29 | ms/batch 18.97 | loss  6.59 | ppl   724.98\n",
      "| epoch   3 |  1600/227772 batches | lr 4.29 | ms/batch 18.72 | loss  6.62 | ppl   749.41\n",
      "| epoch   3 |  1800/227772 batches | lr 4.29 | ms/batch 18.89 | loss  6.67 | ppl   790.79\n",
      "| epoch   3 |  2000/227772 batches | lr 4.29 | ms/batch 18.84 | loss  6.62 | ppl   753.22\n",
      "| epoch   3 |  2200/227772 batches | lr 4.29 | ms/batch 18.73 | loss  6.65 | ppl   775.24\n",
      "| epoch   3 |  2400/227772 batches | lr 4.29 | ms/batch 18.99 | loss  6.60 | ppl   736.47\n",
      "| epoch   3 |  2600/227772 batches | lr 4.29 | ms/batch 19.36 | loss  6.64 | ppl   762.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 52.35s | valid loss  6.83 | valid ppl   924.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |   200/227772 batches | lr 4.07 | ms/batch 18.99 | loss  6.68 | ppl   793.11\n",
      "| epoch   4 |   400/227772 batches | lr 4.07 | ms/batch 18.83 | loss  6.58 | ppl   721.51\n",
      "| epoch   4 |   600/227772 batches | lr 4.07 | ms/batch 18.96 | loss  6.64 | ppl   767.71\n",
      "| epoch   4 |   800/227772 batches | lr 4.07 | ms/batch 18.86 | loss  6.59 | ppl   727.90\n",
      "| epoch   4 |  1000/227772 batches | lr 4.07 | ms/batch 19.06 | loss  6.58 | ppl   723.37\n",
      "| epoch   4 |  1200/227772 batches | lr 4.07 | ms/batch 19.01 | loss  6.57 | ppl   710.85\n",
      "| epoch   4 |  1400/227772 batches | lr 4.07 | ms/batch 19.27 | loss  6.52 | ppl   681.39\n",
      "| epoch   4 |  1600/227772 batches | lr 4.07 | ms/batch 19.17 | loss  6.56 | ppl   703.32\n",
      "| epoch   4 |  1800/227772 batches | lr 4.07 | ms/batch 19.05 | loss  6.57 | ppl   716.74\n",
      "| epoch   4 |  2000/227772 batches | lr 4.07 | ms/batch 18.90 | loss  6.54 | ppl   695.58\n",
      "| epoch   4 |  2200/227772 batches | lr 4.07 | ms/batch 19.13 | loss  6.58 | ppl   718.69\n",
      "| epoch   4 |  2400/227772 batches | lr 4.07 | ms/batch 19.42 | loss  6.51 | ppl   671.37\n",
      "| epoch   4 |  2600/227772 batches | lr 4.07 | ms/batch 18.96 | loss  6.55 | ppl   696.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 52.63s | valid loss  6.71 | valid ppl   821.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |   200/227772 batches | lr 3.87 | ms/batch 18.94 | loss  6.60 | ppl   733.96\n",
      "| epoch   5 |   400/227772 batches | lr 3.87 | ms/batch 18.91 | loss  6.51 | ppl   669.41\n",
      "| epoch   5 |   600/227772 batches | lr 3.87 | ms/batch 19.02 | loss  6.54 | ppl   694.65\n",
      "| epoch   5 |   800/227772 batches | lr 3.87 | ms/batch 18.85 | loss  6.51 | ppl   670.12\n",
      "| epoch   5 |  1000/227772 batches | lr 3.87 | ms/batch 18.95 | loss  6.51 | ppl   669.56\n",
      "| epoch   5 |  1200/227772 batches | lr 3.87 | ms/batch 19.01 | loss  6.47 | ppl   648.69\n",
      "| epoch   5 |  1400/227772 batches | lr 3.87 | ms/batch 18.85 | loss  6.45 | ppl   634.05\n",
      "| epoch   5 |  1600/227772 batches | lr 3.87 | ms/batch 18.99 | loss  6.49 | ppl   657.03\n",
      "| epoch   5 |  1800/227772 batches | lr 3.87 | ms/batch 18.97 | loss  6.51 | ppl   674.69\n",
      "| epoch   5 |  2000/227772 batches | lr 3.87 | ms/batch 18.82 | loss  6.48 | ppl   654.46\n",
      "| epoch   5 |  2200/227772 batches | lr 3.87 | ms/batch 18.95 | loss  6.54 | ppl   691.12\n",
      "| epoch   5 |  2400/227772 batches | lr 3.87 | ms/batch 19.10 | loss  6.45 | ppl   633.12\n",
      "| epoch   5 |  2600/227772 batches | lr 3.87 | ms/batch 18.83 | loss  6.47 | ppl   644.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 52.32s | valid loss  6.87 | valid ppl   962.08\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 5 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_loss = evaluate(model, val_loader)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-rendering",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "freelance-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mintavétel, ami újrasúlyozza a predikciót a temperature változó alapján \n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = torch.log(preds) / temperature\n",
    "    exp_preds = torch.exp(preds)\n",
    "    preds = exp_preds / torch.sum(exp_preds) # Az összes lehetőség egyre szummázódjon (lásd softmax képlet)\n",
    "    probas = torch.multinomial(preds, 1)\n",
    "    return probas, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "flexible-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, b in enumerate(train_loader):\n",
    "    data, targets = b\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "western-transfer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'= valkyria chronicles'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Input:\")\n",
    "' '.join([corpus.vocab.itos[i] for i in data[0].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stopped-command",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'iii'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Target:\")\n",
    "' '.join([corpus.vocab.itos[i] for i in targets[0].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "sound-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = corpus.test[0:in_seq_len].unsqueeze(0).cuda()\n",
    "generated = sentence.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "vital-oakland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text with seed:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'= robert <unk> = robert <unk> is an english film , television and theatre actor . he had a guest @-@ starring role on the television series the bill in 2000 . this was followed by a starring role in'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Generating text with seed:\")\n",
    "' '.join([corpus.vocab.itos[i] for i in generated.transpose(0,1).tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "hourly-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "max_len = 50\n",
    "\n",
    "src = model.emb_encoder(generated) * math.sqrt(model.ninp)\n",
    "src = model.pos_encoder(src)\n",
    "e_output = model.transformer_encoder(src, None)\n",
    "\n",
    "outputs = torch.zeros(max_len).type_as(generated.data)\n",
    "outputs[0] = torch.LongTensor([corpus.vocab.stoi['<sos>']])\n",
    "\n",
    "for i in range(1, max_len):    \n",
    "            \n",
    "        trg_mask = model.generate_square_subsequent_mask(i).to(device)\n",
    "        \n",
    "        trg = model.emb_decoder(outputs[:i].unsqueeze(1)) * math.sqrt(model.ninp)\n",
    "        trg = model.pos_encoder(trg)\n",
    "        \n",
    "        d_output = model.transformer_decoder(trg, e_output, trg_mask, None)\n",
    "        out = model.decoder(d_output)\n",
    "        out, _ = sample(F.softmax(out[-1,:,:], dim=-1)[0], temperature = 1.6)\n",
    "        # out = torch.argmax(F.softmax(out, dim=-1), dim = -1).view(-1)[-1]\n",
    "        \n",
    "        outputs[i] = out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "occupied-vector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<sos> victorian taped county heavily anglian henry confederacy creek fission immutable fez former preparations turbulent box 1963 outgoing kinetics quality persuade fighter 355 00 retreated tv kōsaku geastrum lover turns o2 mediocre turk of infighting pupils next triple instrumentalist set side piccadilly , age overall installations uncle strength rock manager'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Generated text:\")\n",
    "' '.join([corpus.vocab.itos[i] for i in outputs.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-angola",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
